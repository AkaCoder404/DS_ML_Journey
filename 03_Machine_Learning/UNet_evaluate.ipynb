{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet\n",
    "\n",
    "Training, testing, and evaluating the UNet architecture on image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from UNet import UNetNoSkip, UNet, UNetPadded, TGSCustomDataset   \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "device = \"cpu\"    \n",
    "device = torch.device(device)\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "root_dir = os.path.expanduser(\"~/Developer/Datasets/tgs_comp/competition_data/train\")\n",
    "image_folder = \"images/\"\n",
    "mask_folder = \"masks/\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # Change size to 100x100\n",
    "        transforms.Resize((224, 224), antialias=True),\n",
    "    ]\n",
    ")\n",
    "custom_dataset = TGSCustomDataset(root_dir, image_folder, mask_folder, transform)\n",
    "\n",
    "\n",
    "print(\"Train Dataset Size:\", len(custom_dataset))\n",
    "\n",
    "# Image has 4 channels: 3 for RGB and 1 for alpha\n",
    "print(\"Train Image Type\", type(custom_dataset[0][0]), custom_dataset[0][0].shape) \n",
    "print(\"Train Mask Type\", type(custom_dataset[0][1]), custom_dataset[0][1].shape)\n",
    "\n",
    "# Print alpha channel\n",
    "# print(\"Alpha Channel\", custom_dataset[0][1][0][0])\n",
    "\n",
    "# Print Mask\n",
    "print(\"Mask\", custom_dataset[3999][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 2, figsize=(10, 20))\n",
    "visualize_number = 5\n",
    "\n",
    "for i in range(visualize_number):\n",
    "    random_int = np.random.randint(0, len(custom_dataset))\n",
    "    sample = custom_dataset[random_int]\n",
    "    ax1 = axes[i, 0]\n",
    "    ax2 = axes[i, 1]\n",
    "    ax1.set_title(f'Img {custom_dataset.images[i]}')\n",
    "    ax2.set_title(f'Mask {custom_dataset.masks[i]}')\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')\n",
    "        \n",
    "    ax1.imshow(sample[0].permute(1, 2, 0).numpy())  # Convert tensor to numpy array and permute dimensions\n",
    "    ax2.imshow(sample[1].permute(1, 2, 0).numpy(), cmap=\"gray\")  # Convert tensor to numpy array and permute dimensions\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "batch_size = 32\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(custom_dataset))\n",
    "val_size = len(custom_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(custom_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=False, \n",
    "                                            num_workers=4)\n",
    "\n",
    "print(\"Train Loader Size:\", len(train_loader))  # 100 = 3200 / 32\n",
    "print(\"Test Loader Size:\", len(test_loader))    # 25 = 800 / 32\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "# model = UNetNoSkip(in_channels=3, out_channels=1)\n",
    "model = UNetPadded(in_channels=3, out_channels=1, device=device)\n",
    "model = model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "我们使用`dice_coeff`函数来评估图像分割。Dice coefficient测量预测分割和真实分割之间的重叠。Dice为1表示预测分与真实分割完全一致。0表示完全没有重叠。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice_coeff函数\n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.0\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "def train_step(model: nn.Module, data_loader: DataLoader, criterion: nn.Module, optimizer: torch.optim.Optimizer, device: torch.device):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    for i, (images, masks) in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward Pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        outputs = torch.sigmoid(outputs)\n",
    "                \n",
    "        # Backward Pass\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # # Threshold: Binary Mask\n",
    "        # threshold = 0.1\n",
    "        # outputs = (outputs >= threshold).float()\n",
    "        \n",
    "        # Loss\n",
    "        train_loss += loss.item()\n",
    "        train_acc += dice_coeff(outputs, masks)\n",
    "        \n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: nn.Module, data_loader: DataLoader, criterion: nn.Module, device: torch.device):\n",
    "    model.eval()\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    with torch.inference_mode():\n",
    "        for i, (images, masks) in enumerate(data_loader):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            outputs = torch.sigmoid(outputs)   \n",
    "            loss = criterion(outputs, masks)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += dice_coeff(outputs, masks)\n",
    "\n",
    "        train_loss /= len(data_loader)\n",
    "        train_acc /= len(data_loader)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    return train_loss, train_acc\n",
    "        \n",
    "def training(model: nn.Module, \n",
    "                data_loader: DataLoader,\n",
    "                criterion: nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                device: torch.device,\n",
    "                epochs: int\n",
    "            ):\n",
    "    \n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_start_time = time.time()\n",
    "        train_loss, train_acc = train_step(model, data_loader, criterion, optimizer, device)\n",
    "        train_end_time = time.time()\n",
    "        \n",
    "        test_start_time = time.time()\n",
    "        val_loss, val_acc = test_step(model, data_loader, criterion, device)\n",
    "        test_end_time = time.time()\n",
    "        \n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Train Time: {train_end_time - train_start_time:.4f}, Test Time: {test_end_time - test_start_time:.4f}\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = training(model, train_loader, criterion, optimizer, device, EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示训练结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "\n",
    "\n",
    "\n",
    "## IoU Intersection over Union Metric at different Thresholds\n",
    "threshould = 0.5\n",
    "\n",
    "\n",
    "## Precision and Recall at different Thresholds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
